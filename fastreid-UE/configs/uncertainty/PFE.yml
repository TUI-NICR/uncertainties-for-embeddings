_BASE_: ./Base-Uncertainty.yml

MODEL:
  BACKBONE:
    PRETRAIN: False # since we load a checkpoint using WEIGHTS, we do not need to load the ImageNet pretrain in the backbone
    FEAT_DIM: 2048
    FEAT_HW: (16, 8)
  
  WEIGHTS: /results_nas/ange8547/mod_arch/bagtricks # updated in tool script
  CHECKPOINT_REMAP: [[heads.bottleneck.0.*, mean_head.bn.*]]

  HEADS:
    NUM_CLASSES: 751 # used in crown

  MEAN_HEAD:
    NAME: Baseline_mean_head
    POOL_TYPE: GlobalAvgPool

  VAR_HEAD:
    NAME: PFE_var_head
    POOLING_SIZE: (2, 2)

  CROWN:
    NAME: DummyCrown

  FREEZE_WEIGHTS: [backbone]

  LOSSES:
    NAME: ("MutualLikelihoodScoreLoss",)

DATALOADER:
  SAMPLER_TRAIN: NaiveIdentitySampler
  NUM_INSTANCE: 4
  NUM_WORKERS: 8

INPUT:
  SIZE_TRAIN: [ 256, 128 ]
  SIZE_TEST: [ 256, 128 ]

  FLIP:
    ENABLED: True

  REA:
    ENABLED: False
    PROB: 0.5
  
  PADDING:
    ENABLED: False

SOLVER:
  AMP:
    ENABLED: True
  OPT: Adam
  MAX_EPOCH: 50
  BASE_LR: 0.00025
  WEIGHT_DECAY: 0.0005
  WEIGHT_DECAY_NORM: 0.0005
  IMS_PER_BATCH: 64 

  SCHED: MultiStepLR
  STEPS: [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50]
  GAMMA: 0.95

  WARMUP_ITERS: 0
  CHECKPOINT_PERIOD: 1

TEST:
  METRIC: cosine
  EXTRA_END_EVAL: True
  EXTRA_END_EVAL_METRIC: [cosine, sigma_cosine, sqrt_sigma_cosine, euclidean, sigma_euclidean, sqrt_sigma_euclidean, kl_divergence, js_divergence, bhat_distance, wasserstein]
  EVAL_PERIOD: 1

# this is updated in tool script
OUTPUT_DIR: /results_nas/ange8547/mod_arch/PFE